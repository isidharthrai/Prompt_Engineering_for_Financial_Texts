Experiment,Total Samples,Valid Predictions,Accuracy,Macro-F1,Weighted-F1,Macro-Precision,Macro-Recall,MCC,Positive_Precision,Positive_Recall,Positive_F1,Negative_Precision,Negative_Recall,Negative_F1,Neutral_Precision,Neutral_Recall,Neutral_F1,Approach
R1: llama3.1:8b (Zero-Shot),200,200,0.96,0.4401378122308355,0.9707364341085272,0.6649305555555555,0.3931623931623931,0.3893033178646573,0.9947916666666666,0.9794871794871794,0.9870801033591732,0.0,0.0,0.0,1.0,0.2,0.3333333333333333,Zero-Shot
R2: qwen3:8b (Zero-Shot),200,200,0.995,0.9431656720659278,0.9947286160841148,0.9974489795918368,0.9,0.8921425711997711,0.9948979591836736,1.0,0.9974424552429668,0.0,0.0,0.0,1.0,0.8,0.8888888888888888,Zero-Shot
R3: deepseek-r1:8b (Zero-Shot),200,200,0.985,0.5974293059125965,0.9874807197943446,0.5982817869415807,0.5965811965811966,0.7235839492813283,0.9948453608247424,0.9897435897435898,0.9922879177377892,0.0,0.0,0.0,0.8,0.8,0.8,Zero-Shot
R4: Llama3.1:8b (Few-Shot),200,200,0.925,0.4683581219014289,0.9477252843394576,0.4946236559139785,0.4461538461538462,0.221103348498503,0.9838709677419356,0.9384615384615383,0.9606299212598424,0.0,0.0,0.0,0.5,0.4,0.4444444444444444,Few-Shot
R5: Qwen3:8b (Few-Shot),200,200,0.99,0.8974358974358975,0.99,0.8974358974358975,0.8974358974358975,0.7948717948717948,0.9948717948717948,0.9948717948717948,0.9948717948717948,0.0,0.0,0.0,0.8,0.8,0.8,Few-Shot
R6: DeepSeek-R1:8b (Few-Shot),200,200,0.96,0.4939077458659704,0.9696801566579636,0.4545454545454546,0.588034188034188,0.5666851624470428,1.0,0.964102564102564,0.9817232375979112,0.0,0.0,0.0,0.3636363636363636,0.8,0.5,Few-Shot
R7: Llama3.1:8b (CoT),200,200,0.95,0.4375359815774324,0.9631260794473228,0.6631762652705061,0.3897435897435897,0.2889899840889748,0.9895287958115184,0.9692307692307692,0.9792746113989638,0.0,0.0,0.0,1.0,0.2,0.3333333333333333,Chain-of-Thought
R8: Qwen3:8b (CoT),200,200,0.995,0.9431656720659278,0.9947286160841148,0.9974489795918368,0.9,0.8921425711997711,0.9948979591836736,1.0,0.9974424552429668,0.0,0.0,0.0,1.0,0.8,0.8888888888888888,Chain-of-Thought
R9: DeepSeek-R1:8b (CoT),200,200,0.95,0.5,0.9625,0.4523809523809524,0.6495726495726496,0.5624544450105448,1.0,0.9487179487179488,0.9736842105263158,0.0,0.0,0.0,0.3571428571428571,1.0,0.5263157894736842,Chain-of-Thought
R10: Llama3.1:8b (ToT),200,200,0.74,0.2859903381642512,0.8365217391304347,0.3288888888888889,0.252991452991453,0.05921092059395465,0.9866666666666667,0.7589743589743589,0.8579710144927536,0.0,0.0,0.0,0.0,0.0,0.0,Tree-of-Thought
R11: Qwen3:8b (ToT),200,200,0.98,0.8281786941580755,0.9816151202749142,0.7831236121391562,0.8923076923076924,0.6665480355267144,0.9948186528497409,0.9846153846153847,0.9896907216494846,0.0,0.0,0.0,0.5714285714285714,0.8,0.6666666666666666,Tree-of-Thought
R12: DeepSeek-R1:8b (ToT),200,200,0.975,0.5512489233419466,0.9790697674418606,0.5220734126984127,0.5931623931623932,0.6216623662236674,0.9947916666666666,0.9794871794871794,0.9870801033591732,0.0,0.0,0.0,0.5714285714285714,0.8,0.6666666666666666,Tree-of-Thought
