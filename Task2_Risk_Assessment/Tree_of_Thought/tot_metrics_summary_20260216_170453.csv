Experiment,Total Samples,Valid Predictions,Accuracy,Macro-F1,Weighted-F1,Macro-Precision,Macro-Recall,MCC,Positive_Precision,Positive_Recall,Positive_F1,Negative_Precision,Negative_Recall,Negative_F1,Neutral_Precision,Neutral_Recall,Neutral_F1
R10: Llama3.1:8b (ToT),200,200,0.74,0.2859903381642512,0.8365217391304347,0.3288888888888889,0.252991452991453,0.05921092059395465,0.9866666666666667,0.7589743589743589,0.8579710144927536,0.0,0.0,0.0,0.0,0.0,0.0
R11: Qwen3:8b (ToT),200,200,0.98,0.8281786941580755,0.9816151202749142,0.7831236121391562,0.8923076923076924,0.6665480355267144,0.9948186528497409,0.9846153846153847,0.9896907216494846,0.0,0.0,0.0,0.5714285714285714,0.8,0.6666666666666666
R12: DeepSeek-R1:8b (ToT),200,200,0.975,0.5512489233419466,0.9790697674418606,0.5220734126984127,0.5931623931623932,0.6216623662236674,0.9947916666666666,0.9794871794871794,0.9870801033591732,0.0,0.0,0.0,0.5714285714285714,0.8,0.6666666666666666
