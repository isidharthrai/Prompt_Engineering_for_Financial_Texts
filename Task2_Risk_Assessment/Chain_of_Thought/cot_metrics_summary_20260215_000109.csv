Experiment,Total Samples,Valid Predictions,Accuracy,Macro-F1,Weighted-F1,Macro-Precision,Macro-Recall,MCC,Positive_Precision,Positive_Recall,Positive_F1,Negative_Precision,Negative_Recall,Negative_F1,Neutral_Precision,Neutral_Recall,Neutral_F1
R7: Llama3.1:8b (CoT),200,200,0.95,0.4375359815774324,0.9631260794473229,0.6631762652705061,0.38974358974358975,0.28898998408897486,0.9895287958115183,0.9692307692307692,0.9792746113989638,0.0,0.0,0.0,1.0,0.2,0.3333333333333333
R8: Qwen3:8b (CoT),200,200,0.995,0.9431656720659278,0.9947286160841148,0.9974489795918368,0.9,0.8921425711997711,0.9948979591836735,1.0,0.9974424552429667,0.0,0.0,0.0,1.0,0.8,0.8888888888888888
R9: DeepSeek-R1:8b (CoT),200,200,0.95,0.5,0.9625,0.4523809523809524,0.6495726495726496,0.5624544450105448,1.0,0.9487179487179487,0.9736842105263158,0.0,0.0,0.0,0.35714285714285715,1.0,0.5263157894736842
